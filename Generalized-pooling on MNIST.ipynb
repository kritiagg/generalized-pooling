{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import ipdb\n",
    "%matplotlib inline\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"1\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gated Pooling "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from keras import backend as K\n",
    "\n",
    "# Add new layer in Keras\n",
    "# https://keunwoochoi.wordpress.com/2016/11/18/for-beginners-writing-a-custom-keras-layer/\n",
    "# define gated max-average pooling lyaer\n",
    "class GatedPooling2D(MaxPooling2D):\n",
    "    def call(self, inputs, fil=32, size =2, learn_option='l/c', mask=None, data_format = 'tf'):\n",
    "        \"\"\"Gated pooling operation, responsive\n",
    "        Combine max pooling and average pooling in a mixing proportion,\n",
    "        which is obtained from the inner product between the gating mask and the region being\n",
    "        pooled and then fed through a sigmoid:\n",
    "           fgate(x) =  sigmoid(w*x)* fmax(x) + (1-sigmoid(w*x))* favg(x)\n",
    "           arguments:\n",
    "             inputs: input of shape [batch size, height, width, channels]\n",
    "             filter: filter size of the input layer, used to initialize gating mask\n",
    "             size: an integer, width and height of the pooling filter\n",
    "             learn_option: learning options of gated pooling, include:\n",
    "                            'l/c': learn a mask per layer/channel\n",
    "                            'l/r/c': learn a mask per layer/pooling region/channel combined\n",
    "           return:\n",
    "             outputs: tensor with the shape of [batch_size, height//size, width//size, channels]\n",
    "        \"\"\"\n",
    "        if learn_option == 'l':\n",
    "            gating_mask = all_channel_connected2d(inputs)\n",
    "        if learn_option == 'l/c':\n",
    "            w_gated = tf.Variable(tf.truncated_normal([size,size,fil,fil]))\n",
    "            gating_mask = K.conv2d(inputs, w_gated, strides=(size,size), padding=self.padding)\n",
    "        if learn_option == 'l/r/c':\n",
    "            gating_mask = locally_connected2d(inputs)\n",
    "\n",
    "        alpha = tf.sigmoid(gating_mask)\n",
    "\n",
    "        x1 = K.pool2d(inputs, pool_size = (size, size), strides=(2,2), padding=self.padding, data_format=self.data_format, pool_mode = \"max\")\n",
    "        x2 = K.pool2d(inputs,  pool_size = (size, size), strides=(2,2), padding=self.padding, data_format=self.data_format, pool_mode= \"avg\")\n",
    "        outputs = tf.add(tf.multiply(x1, alpha), tf.multiply(x2, (1-alpha)))\n",
    "        return outputs\n",
    "\n",
    "\n",
    "    #locally connected layer (unshared-weights conv, layer),\n",
    "    # designed for gated pooling, learn a param \"per layer/region/channel\"\n",
    "    def locally_connected2d(x, size = 2):\n",
    "        \"\"\"\n",
    "        The `LocallyConnected2D` layer works similarly\n",
    "        to the `Convolution2D` layer, except that weights are unshared,\n",
    "        that is, a different set of filters is applied at each\n",
    "        different patch of the input.\n",
    "        NOTE: No bias or activation function applied. No overlapping between sub-region.\n",
    "        arguments:\n",
    "            x: 4D tensor with shape: [samples, rows, cols, channels]\n",
    "            size: width and height of the filter, default 2x2 filter.\n",
    "                  this is also the length of stride to ensure no overlapping\n",
    "        returns:\n",
    "            4D tensor with shape: [samples, new_rows, new_cols, nb_filter]\n",
    "            `rows` and `cols` values might have changed due to padding.\n",
    "        \"\"\"\n",
    "\n",
    "        xs = []\n",
    "        _, input_row, input_col, nb_filter = x.get_shape().as_list()\n",
    "        output_row = input_row //2\n",
    "        output_col = input_col //2\n",
    "        nb_row = size\n",
    "        nb_col = size\n",
    "        stride_row = size\n",
    "        stride_col = size\n",
    "        feature_dim = nb_row * nb_col * nb_filter\n",
    "\n",
    "        w_shape = (output_row * output_col,\n",
    "                   nb_row * nb_col * nb_filter,\n",
    "                   nb_filter)\n",
    "        mask = tf.Variable(tf.truncated_normal(w_shape, stddev=2./(w_shape[0]*w_shape[1]*2)**0.5))\n",
    "        for i in range(output_row):\n",
    "            for j in range(output_col):\n",
    "                slice_row = slice(i * stride_row,\n",
    "                                  i * stride_row + nb_row)\n",
    "                slice_col = slice(j * stride_col,\n",
    "                                  j * stride_col + nb_col)\n",
    "                xs.append(tf.reshape(x[:, slice_row, slice_col, :], (1, -1, feature_dim)))\n",
    "        x_aggregate = tf.concat(0, xs)\n",
    "        output = tf.matmul(x_aggregate, mask)\n",
    "        output = tf.reshape(output, (output_row, output_col, -1, nb_filter))\n",
    "        output = tf.transpose(output, perm=[2, 0, 1, 3])\n",
    "\n",
    "        return output\n",
    "\n",
    "\n",
    "\n",
    "    #design for gated pooling, learn a param \"per layer\" option\n",
    "    def all_channel_connected2d(x, size=2):\n",
    "        \"\"\"\n",
    "        The all channel connected layer is a modified version of\n",
    "        Convolutional layer,\n",
    "        which shares the same weights not only between each patch,\n",
    "        but also between all channels of the layer input. That is,\n",
    "        the whole layer only has one filter\n",
    "        NOTE: 'VALID', no bias, no activation function.\n",
    "        arguments:\n",
    "            x: 4D tensor with shape: [batch_size, rows, cols, channels]\n",
    "            size: width and height of the filter, default 2x2 filter.\n",
    "                  this is also the length of stride to ensure no overlapping\n",
    "        returns:\n",
    "            4D tensor with shape: [batch_size, new_rows, new_cols, nb_filter]\n",
    "        \"\"\"\n",
    "\n",
    "        nb_batch, input_row, input_col, nb_filter = x.get_shape().as_list()\n",
    "        output_size = input_row //2\n",
    "        mask = tf.Variable(tf.truncated_normal([size,size,1,1], stddev=2./(size*size*2)**0.5))\n",
    "\n",
    "        xs = []\n",
    "        for c in tf.split(x, nb_filter, 3):\n",
    "            xs.append(tf.nn.conv2d(c, mask, strides=[1,1,1,1], padding='VALID'))\n",
    "        output = tf.reshape(x, [nb_batch, output_size, output_size, nb_filter])\n",
    "\n",
    "        return output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Mixed Pooling "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from keras.engine.topology import Layer\n",
    "from keras import backend as K\n",
    "from keras.layers import MaxPooling2D\n",
    "\n",
    "# define mixed max-average pooling layer\n",
    "class MixedPooling2D(MaxPooling2D):\n",
    "    def call(self, inputs, alpha = -1, size =2, mask=None, data_format = 'tf'):\n",
    "        \n",
    "    # def mixed_pooling (inputs, alpha, size=2):\n",
    "        \"\"\"Mixed pooling operation, nonresponsive\n",
    "           Combine max pooling and average pooling in fixed proportion specified by alpha a:\n",
    "            f mixed (x) = a * f max(x) + (1-a) * f avg(x)\n",
    "            arguments:\n",
    "              inputs: tensor of shape [batch size, height, width, channels]\n",
    "              size: an integer, width and height of the pooling filter\n",
    "              alpha: the scalar mixing proportion of range [0,1]\n",
    "            return:\n",
    "              outputs: tensor of shape [batch_size, height//size, width//size, channels]\n",
    "        \"\"\"\n",
    "\n",
    "        if alpha == -1:\n",
    "            alpha = tf.Variable(0.0)\n",
    "        x1 = K.pool2d(inputs, pool_size = (size, size), strides=(2,2), padding=self.padding, data_format=self.data_format, pool_mode = \"max\")\n",
    "        x2 = K.pool2d(inputs,  pool_size = (size, size), strides=(2,2), padding=self.padding, data_format=self.data_format, pool_mode= \"avg\")\n",
    "        outputs = tf.add(tf.multiply(x1, alpha), tf.multiply(x2, (1-alpha)))\n",
    "\n",
    "        return outputs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "MNIST_data = '../STN-exp/MNIST-data/'\n",
    "model_dir = '../STN-exp/models/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "## setup_mnist.py -- mnist data and model loading code\n",
    "##\n",
    "## Copyright (C) 2016, Nicholas Carlini <nicholas@carlini.com>.\n",
    "##\n",
    "## This program is licenced under the BSD 2-Clause licence,\n",
    "## contained in the LICENCE file in this directory.\n",
    "\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import os\n",
    "import pickle\n",
    "import gzip\n",
    "import urllib\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation, Flatten\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras.utils import np_utils\n",
    "from keras.models import load_model\n",
    "\n",
    "def extract_data(filename, num_images):\n",
    "    with gzip.open(filename) as bytestream:\n",
    "        bytestream.read(16)\n",
    "        buf = bytestream.read(num_images*28*28)\n",
    "        data = np.frombuffer(buf, dtype=np.uint8).astype(np.float32)\n",
    "        data = (data / 255) - 0.5\n",
    "        data = data.reshape(num_images, 28, 28, 1)\n",
    "        return data\n",
    "\n",
    "def extract_labels(filename, num_images):\n",
    "    with gzip.open(filename) as bytestream:\n",
    "        bytestream.read(8)\n",
    "        buf = bytestream.read(1 * num_images)\n",
    "        labels = np.frombuffer(buf, dtype=np.uint8)\n",
    "    return (np.arange(10) == labels[:, None]).astype(np.float32)\n",
    "\n",
    "class MNIST:\n",
    "    def __init__(self):\n",
    "        if not os.path.exists(MNIST_data):\n",
    "            os.mkdir(MNIST_data)\n",
    "            files = [\"train-images-idx3-ubyte.gz\",\n",
    "                     \"t10k-images-idx3-ubyte.gz\",\n",
    "                     \"train-labels-idx1-ubyte.gz\",\n",
    "                     \"t10k-labels-idx1-ubyte.gz\"]\n",
    "            for name in files:\n",
    "\n",
    "                urllib.urlretrieve('http://yann.lecun.com/exdb/mnist/' + name, \"MNIST_data/\"+name)\n",
    "\n",
    "        train_data = extract_data(MNIST_data + \"//train-images-idx3-ubyte.gz\", 60000)\n",
    "        train_labels = extract_labels(MNIST_data + \"/train-labels-idx1-ubyte.gz\", 60000)\n",
    "        self.test_data = extract_data(MNIST_data + \"/t10k-images-idx3-ubyte.gz\", 10000)\n",
    "        self.test_labels = extract_labels(MNIST_data + \"/t10k-labels-idx1-ubyte.gz\", 10000)\n",
    "        \n",
    "        VALIDATION_SIZE = 5000\n",
    "        \n",
    "        self.validation_data = train_data[:VALIDATION_SIZE, :, :, :]\n",
    "        self.validation_labels = train_labels[:VALIDATION_SIZE]\n",
    "        self.train_data = train_data[VALIDATION_SIZE:, :, :, :]\n",
    "        self.train_labels = train_labels[VALIDATION_SIZE:]\n",
    "        self.num_classes = train_labels[1:]\n",
    "\n",
    "        \n",
    "MNIST_adv_data = '../STN-exp/mnist_adv_data'\n",
    "class MNIST_Adv:\n",
    "    def __init__(self):\n",
    "        if not os.path.exists(MNIST_data):\n",
    "            os.mkdir(MNIST_data)\n",
    "        data = MNIST()\n",
    "        train_data = np.load(MNIST_adv_data+\"/adv_inputs.npy\")\n",
    "        train_labels = np.load(MNIST_adv_data+\"/true_labels.npy\")\n",
    "#         train_targets = np.load(MNIST_adv_data+\"/adv_targets.npy\")\n",
    "        train_data = np.concatenate((train_data, data.train_data))\n",
    "        train_labels = np.concatenate((train_labels, data.train_labels))\n",
    "        VALIDATION_SIZE = 90\n",
    "        \n",
    "        self.validation_data = train_data[:VALIDATION_SIZE, :, :, :]\n",
    "        self.validation_labels = train_labels[:VALIDATION_SIZE]\n",
    "        self.train_data = train_data[VALIDATION_SIZE:, :, :, :]\n",
    "        self.train_labels = train_labels[VALIDATION_SIZE:]\n",
    "        self.num_classes = train_labels[1:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train normal baseline models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation, Flatten, Input\n",
    "from keras.layers import Conv2D, MaxPooling2D, AveragePooling2D\n",
    "from keras.optimizers import SGD\n",
    "from keras.models import Model\n",
    "\n",
    "import tensorflow as tf\n",
    "# from setup_mnist import MNIST\n",
    "# from setup_cifar import CIFAR\n",
    "import os\n",
    "\n",
    "def train_normal(data, file_name, params, num_epochs=50, batch_size=128, train_temp=1, init=None):\n",
    "\n",
    "    model = Sequential()\n",
    "    model.add(Conv2D(params[0], (3, 3),\n",
    "                            input_shape=data.train_data.shape[1:]))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Conv2D(params[1], (3, 3)))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(MaxPooling2D(pool_size = (2,2) ))\n",
    "    \n",
    "    model.add(Conv2D(params[2], (3, 3)))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Conv2D(params[3], (3, 3)))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(MaxPooling2D(pool_size = (2,2)  ))\n",
    "\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(params[4]))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(params[5]))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Dense(10))\n",
    "    # no softmax\n",
    "    \n",
    "    print(model.summary)\n",
    "   \n",
    "    if init != None:\n",
    "        model.load_weights(init)\n",
    "\n",
    "    def fn(correct, predicted):\n",
    "        return tf.nn.softmax_cross_entropy_with_logits(labels=correct,\n",
    "                                                       logits=predicted/train_temp)\n",
    "\n",
    "    sgd = SGD(lr=0.01, decay=1e-6, momentum=0.9, nesterov=True)\n",
    "    \n",
    "    model.compile(loss=fn,\n",
    "                  optimizer=sgd,\n",
    "                  metrics=['accuracy'])\n",
    "    \n",
    "    model.fit(data.train_data, data.train_labels,\n",
    "              batch_size=batch_size,\n",
    "              validation_data=(data.validation_data, data.validation_labels),\n",
    "              epochs=num_epochs,\n",
    "              shuffle=True)\n",
    "    \n",
    "\n",
    "    if file_name != None:\n",
    "        model.save(file_name)\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Normal baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<bound method Sequential.summary of <keras.models.Sequential object at 0x7f35a21caa50>>\n",
      "Train on 55000 samples, validate on 5000 samples\n",
      "Epoch 1/50\n",
      "55000/55000 [==============================] - 9s 157us/step - loss: 0.6366 - acc: 0.7950 - val_loss: 0.0989 - val_acc: 0.9698\n",
      "Epoch 2/50\n",
      "55000/55000 [==============================] - 8s 147us/step - loss: 0.1214 - acc: 0.9629 - val_loss: 0.0609 - val_acc: 0.9810\n",
      "Epoch 3/50\n",
      "55000/55000 [==============================] - 8s 146us/step - loss: 0.0868 - acc: 0.9734 - val_loss: 0.0535 - val_acc: 0.9846\n",
      "Epoch 4/50\n",
      "55000/55000 [==============================] - 8s 147us/step - loss: 0.0677 - acc: 0.9795 - val_loss: 0.0468 - val_acc: 0.9868\n",
      "Epoch 5/50\n",
      "55000/55000 [==============================] - 8s 147us/step - loss: 0.0588 - acc: 0.9825 - val_loss: 0.0382 - val_acc: 0.9898\n",
      "Epoch 6/50\n",
      "55000/55000 [==============================] - 8s 147us/step - loss: 0.0499 - acc: 0.9849 - val_loss: 0.0338 - val_acc: 0.9902\n",
      "Epoch 7/50\n",
      "55000/55000 [==============================] - 8s 147us/step - loss: 0.0438 - acc: 0.9863 - val_loss: 0.0336 - val_acc: 0.9910\n",
      "Epoch 8/50\n",
      "55000/55000 [==============================] - 8s 148us/step - loss: 0.0408 - acc: 0.9876 - val_loss: 0.0349 - val_acc: 0.9918\n",
      "Epoch 9/50\n",
      "55000/55000 [==============================] - 8s 148us/step - loss: 0.0336 - acc: 0.9892 - val_loss: 0.0321 - val_acc: 0.9922\n",
      "Epoch 10/50\n",
      "55000/55000 [==============================] - 8s 147us/step - loss: 0.0319 - acc: 0.9901 - val_loss: 0.0325 - val_acc: 0.9902\n",
      "Epoch 11/50\n",
      "55000/55000 [==============================] - 8s 147us/step - loss: 0.0314 - acc: 0.9903 - val_loss: 0.0310 - val_acc: 0.9922\n",
      "Epoch 12/50\n",
      "55000/55000 [==============================] - 8s 147us/step - loss: 0.0266 - acc: 0.9916 - val_loss: 0.0331 - val_acc: 0.9918\n",
      "Epoch 13/50\n",
      "55000/55000 [==============================] - 8s 147us/step - loss: 0.0231 - acc: 0.9930 - val_loss: 0.0306 - val_acc: 0.9926\n",
      "Epoch 14/50\n",
      "55000/55000 [==============================] - 8s 147us/step - loss: 0.0230 - acc: 0.9924 - val_loss: 0.0304 - val_acc: 0.9918\n",
      "Epoch 15/50\n",
      "55000/55000 [==============================] - 8s 146us/step - loss: 0.0208 - acc: 0.9933 - val_loss: 0.0323 - val_acc: 0.9918\n",
      "Epoch 16/50\n",
      "55000/55000 [==============================] - 8s 147us/step - loss: 0.0203 - acc: 0.9937 - val_loss: 0.0315 - val_acc: 0.9922\n",
      "Epoch 17/50\n",
      "55000/55000 [==============================] - 8s 147us/step - loss: 0.0181 - acc: 0.9944 - val_loss: 0.0290 - val_acc: 0.9926\n",
      "Epoch 18/50\n",
      "55000/55000 [==============================] - 8s 147us/step - loss: 0.0177 - acc: 0.9943 - val_loss: 0.0343 - val_acc: 0.9920\n",
      "Epoch 19/50\n",
      "55000/55000 [==============================] - 8s 147us/step - loss: 0.0167 - acc: 0.9946 - val_loss: 0.0306 - val_acc: 0.9928\n",
      "Epoch 20/50\n",
      "55000/55000 [==============================] - 8s 147us/step - loss: 0.0154 - acc: 0.9950 - val_loss: 0.0317 - val_acc: 0.9930\n",
      "Epoch 21/50\n",
      "55000/55000 [==============================] - 8s 147us/step - loss: 0.0142 - acc: 0.9954 - val_loss: 0.0327 - val_acc: 0.9922\n",
      "Epoch 22/50\n",
      "55000/55000 [==============================] - 8s 147us/step - loss: 0.0146 - acc: 0.9951 - val_loss: 0.0326 - val_acc: 0.9924\n",
      "Epoch 23/50\n",
      "55000/55000 [==============================] - 8s 147us/step - loss: 0.0127 - acc: 0.9959 - val_loss: 0.0321 - val_acc: 0.9926\n",
      "Epoch 24/50\n",
      "55000/55000 [==============================] - 8s 147us/step - loss: 0.0123 - acc: 0.9958 - val_loss: 0.0304 - val_acc: 0.9926\n",
      "Epoch 25/50\n",
      "55000/55000 [==============================] - 8s 147us/step - loss: 0.0112 - acc: 0.9964 - val_loss: 0.0308 - val_acc: 0.9932\n",
      "Epoch 26/50\n",
      "55000/55000 [==============================] - 8s 148us/step - loss: 0.0100 - acc: 0.9968 - val_loss: 0.0325 - val_acc: 0.9934\n",
      "Epoch 27/50\n",
      "55000/55000 [==============================] - 8s 147us/step - loss: 0.0101 - acc: 0.9965 - val_loss: 0.0317 - val_acc: 0.9924\n",
      "Epoch 28/50\n",
      "55000/55000 [==============================] - 8s 147us/step - loss: 0.0098 - acc: 0.9968 - val_loss: 0.0310 - val_acc: 0.9942\n",
      "Epoch 29/50\n",
      "55000/55000 [==============================] - 8s 147us/step - loss: 0.0094 - acc: 0.9968 - val_loss: 0.0319 - val_acc: 0.9922\n",
      "Epoch 30/50\n",
      "55000/55000 [==============================] - 8s 147us/step - loss: 0.0098 - acc: 0.9968 - val_loss: 0.0308 - val_acc: 0.9930\n",
      "Epoch 31/50\n",
      "55000/55000 [==============================] - 8s 147us/step - loss: 0.0094 - acc: 0.9966 - val_loss: 0.0331 - val_acc: 0.9932\n",
      "Epoch 32/50\n",
      "55000/55000 [==============================] - 8s 147us/step - loss: 0.0073 - acc: 0.9977 - val_loss: 0.0343 - val_acc: 0.9934\n",
      "Epoch 33/50\n",
      "55000/55000 [==============================] - 8s 146us/step - loss: 0.0086 - acc: 0.9971 - val_loss: 0.0312 - val_acc: 0.9932\n",
      "Epoch 34/50\n",
      "55000/55000 [==============================] - 8s 147us/step - loss: 0.0085 - acc: 0.9973 - val_loss: 0.0337 - val_acc: 0.9930\n",
      "Epoch 35/50\n",
      "55000/55000 [==============================] - 8s 147us/step - loss: 0.0080 - acc: 0.9971 - val_loss: 0.0350 - val_acc: 0.9922\n",
      "Epoch 36/50\n",
      "55000/55000 [==============================] - 8s 148us/step - loss: 0.0078 - acc: 0.9971 - val_loss: 0.0321 - val_acc: 0.9926\n",
      "Epoch 37/50\n",
      "55000/55000 [==============================] - 8s 147us/step - loss: 0.0083 - acc: 0.9972 - val_loss: 0.0340 - val_acc: 0.9936\n",
      "Epoch 38/50\n",
      "55000/55000 [==============================] - 8s 147us/step - loss: 0.0063 - acc: 0.9977 - val_loss: 0.0388 - val_acc: 0.9920\n",
      "Epoch 39/50\n",
      "55000/55000 [==============================] - 8s 147us/step - loss: 0.0064 - acc: 0.9977 - val_loss: 0.0373 - val_acc: 0.9930\n",
      "Epoch 40/50\n",
      "55000/55000 [==============================] - 8s 147us/step - loss: 0.0069 - acc: 0.9977 - val_loss: 0.0320 - val_acc: 0.9930\n",
      "Epoch 41/50\n",
      "55000/55000 [==============================] - 8s 147us/step - loss: 0.0054 - acc: 0.9981 - val_loss: 0.0326 - val_acc: 0.9932\n",
      "Epoch 42/50\n",
      "55000/55000 [==============================] - 8s 147us/step - loss: 0.0051 - acc: 0.9981 - val_loss: 0.0386 - val_acc: 0.9936\n",
      "Epoch 43/50\n",
      "55000/55000 [==============================] - 8s 147us/step - loss: 0.0061 - acc: 0.9979 - val_loss: 0.0369 - val_acc: 0.9936\n",
      "Epoch 44/50\n",
      "55000/55000 [==============================] - 8s 147us/step - loss: 0.0060 - acc: 0.9980 - val_loss: 0.0348 - val_acc: 0.9934\n",
      "Epoch 45/50\n",
      "55000/55000 [==============================] - 8s 147us/step - loss: 0.0059 - acc: 0.9982 - val_loss: 0.0352 - val_acc: 0.9936\n",
      "Epoch 46/50\n",
      "55000/55000 [==============================] - 8s 148us/step - loss: 0.0050 - acc: 0.9984 - val_loss: 0.0337 - val_acc: 0.9936\n",
      "Epoch 47/50\n",
      "55000/55000 [==============================] - 8s 147us/step - loss: 0.0047 - acc: 0.9983 - val_loss: 0.0376 - val_acc: 0.9930\n",
      "Epoch 48/50\n",
      "55000/55000 [==============================] - 8s 147us/step - loss: 0.0050 - acc: 0.9983 - val_loss: 0.0313 - val_acc: 0.9936\n",
      "Epoch 49/50\n",
      "55000/55000 [==============================] - 8s 147us/step - loss: 0.0038 - acc: 0.9987 - val_loss: 0.0388 - val_acc: 0.9940\n",
      "Epoch 50/50\n",
      "55000/55000 [==============================] - 8s 147us/step - loss: 0.0047 - acc: 0.9984 - val_loss: 0.0378 - val_acc: 0.9930\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.models.Sequential at 0x7f35a21caa50>"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "if not os.path.isdir(model_dir):\n",
    "    os.makedirs(model_dir)\n",
    "\n",
    "train_normal(MNIST(), model_dir+\"/mnist_baseline\", [32, 32, 64, 64, 200, 200], num_epochs=50)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# normal baseline on adv examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "if not os.path.isdir(model_dir):\n",
    "    os.makedirs(model_dir)\n",
    "\n",
    "train_normal(MNIST_Adv(), model_dir+\"/mnist_baseline_adv\", [32, 32, 64, 64, 200, 200], num_epochs=50, init = None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train Mixed Pooilng models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation, Flatten, Input\n",
    "from keras.layers import Conv2D, MaxPooling2D, AveragePooling2D\n",
    "from keras.optimizers import SGD\n",
    "from keras.models import Model\n",
    "\n",
    "import tensorflow as tf\n",
    "# from setup_mnist import MNIST\n",
    "# from setup_cifar import CIFAR\n",
    "import os\n",
    "\n",
    "def train(data, file_name, params, num_epochs=50, batch_size=128, train_temp=1, init=None):\n",
    "\n",
    "    model = Sequential()\n",
    "    model.add(Conv2D(params[0], (3, 3),\n",
    "                            input_shape=data.train_data.shape[1:]))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Conv2D(params[1], (3, 3)))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(MixedPooling2D( ))\n",
    "    \n",
    "    model.add(Conv2D(params[2], (3, 3)))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Conv2D(params[3], (3, 3)))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(MixedPooling2D( ))\n",
    "\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(params[4]))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(params[5]))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Dense(10))\n",
    "    # no softmax\n",
    "    \n",
    "    print(model.summary)\n",
    "   \n",
    "    if init != None:\n",
    "        model.load_weights(init)\n",
    "\n",
    "    def fn(correct, predicted):\n",
    "        return tf.nn.softmax_cross_entropy_with_logits(labels=correct,\n",
    "                                                       logits=predicted/train_temp)\n",
    "\n",
    "    sgd = SGD(lr=0.01, decay=1e-6, momentum=0.9, nesterov=True)\n",
    "    \n",
    "    model.compile(loss=fn,\n",
    "                  optimizer=sgd,\n",
    "                  metrics=['accuracy'])\n",
    "    \n",
    "    model.fit(data.train_data, data.train_labels,\n",
    "              batch_size=batch_size,\n",
    "              validation_data=(data.validation_data, data.validation_labels),\n",
    "              epochs=num_epochs,\n",
    "              shuffle=True)\n",
    "    \n",
    "\n",
    "    if file_name != None:\n",
    "        model.save(file_name)\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Mixed Baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<bound method Sequential.summary of <keras.models.Sequential object at 0x7f359b0a8e50>>\n",
      "Train on 55000 samples, validate on 5000 samples\n",
      "Epoch 1/50\n",
      "55000/55000 [==============================] - 9s 171us/step - loss: 0.6502 - acc: 0.7813 - val_loss: 0.1236 - val_acc: 0.9630\n",
      "Epoch 2/50\n",
      "55000/55000 [==============================] - 9s 158us/step - loss: 0.1582 - acc: 0.9521 - val_loss: 0.0786 - val_acc: 0.9782\n",
      "Epoch 3/50\n",
      "55000/55000 [==============================] - 9s 158us/step - loss: 0.1147 - acc: 0.9651 - val_loss: 0.0709 - val_acc: 0.9798\n",
      "Epoch 4/50\n",
      "55000/55000 [==============================] - 9s 158us/step - loss: 0.0911 - acc: 0.9722 - val_loss: 0.0586 - val_acc: 0.9826\n",
      "Epoch 5/50\n",
      "55000/55000 [==============================] - 9s 158us/step - loss: 0.0793 - acc: 0.9757 - val_loss: 0.0537 - val_acc: 0.9848\n",
      "Epoch 6/50\n",
      "55000/55000 [==============================] - 9s 158us/step - loss: 0.0675 - acc: 0.9796 - val_loss: 0.0489 - val_acc: 0.9864\n",
      "Epoch 7/50\n",
      "55000/55000 [==============================] - 9s 158us/step - loss: 0.0591 - acc: 0.9813 - val_loss: 0.0483 - val_acc: 0.9870\n",
      "Epoch 8/50\n",
      "55000/55000 [==============================] - 9s 158us/step - loss: 0.0542 - acc: 0.9831 - val_loss: 0.0474 - val_acc: 0.9860\n",
      "Epoch 9/50\n",
      "55000/55000 [==============================] - 9s 158us/step - loss: 0.0508 - acc: 0.9840 - val_loss: 0.0431 - val_acc: 0.9894\n",
      "Epoch 10/50\n",
      "55000/55000 [==============================] - 9s 158us/step - loss: 0.0458 - acc: 0.9860 - val_loss: 0.0374 - val_acc: 0.9906\n",
      "Epoch 11/50\n",
      "55000/55000 [==============================] - 9s 158us/step - loss: 0.0439 - acc: 0.9865 - val_loss: 0.0373 - val_acc: 0.9906\n",
      "Epoch 12/50\n",
      "55000/55000 [==============================] - 9s 159us/step - loss: 0.0379 - acc: 0.9882 - val_loss: 0.0395 - val_acc: 0.9900\n",
      "Epoch 13/50\n",
      "55000/55000 [==============================] - 9s 158us/step - loss: 0.0365 - acc: 0.9884 - val_loss: 0.0386 - val_acc: 0.9896\n",
      "Epoch 14/50\n",
      "55000/55000 [==============================] - 9s 158us/step - loss: 0.0337 - acc: 0.9892 - val_loss: 0.0373 - val_acc: 0.9906\n",
      "Epoch 15/50\n",
      "55000/55000 [==============================] - 9s 158us/step - loss: 0.0322 - acc: 0.9897 - val_loss: 0.0337 - val_acc: 0.9916\n",
      "Epoch 16/50\n",
      "55000/55000 [==============================] - 9s 158us/step - loss: 0.0294 - acc: 0.9904 - val_loss: 0.0346 - val_acc: 0.9914\n",
      "Epoch 17/50\n",
      "55000/55000 [==============================] - 9s 158us/step - loss: 0.0274 - acc: 0.9913 - val_loss: 0.0306 - val_acc: 0.9912\n",
      "Epoch 18/50\n",
      "55000/55000 [==============================] - 9s 158us/step - loss: 0.0253 - acc: 0.9919 - val_loss: 0.0371 - val_acc: 0.9910\n",
      "Epoch 19/50\n",
      "55000/55000 [==============================] - 9s 158us/step - loss: 0.0243 - acc: 0.9924 - val_loss: 0.0352 - val_acc: 0.9910\n",
      "Epoch 20/50\n",
      "55000/55000 [==============================] - 9s 158us/step - loss: 0.0236 - acc: 0.9925 - val_loss: 0.0365 - val_acc: 0.9916\n",
      "Epoch 21/50\n",
      "55000/55000 [==============================] - 9s 158us/step - loss: 0.0236 - acc: 0.9923 - val_loss: 0.0348 - val_acc: 0.9924\n",
      "Epoch 22/50\n",
      "55000/55000 [==============================] - 9s 158us/step - loss: 0.0211 - acc: 0.9935 - val_loss: 0.0355 - val_acc: 0.9924\n",
      "Epoch 23/50\n",
      "55000/55000 [==============================] - 9s 159us/step - loss: 0.0197 - acc: 0.9939 - val_loss: 0.0317 - val_acc: 0.9922\n",
      "Epoch 24/50\n",
      "55000/55000 [==============================] - 9s 158us/step - loss: 0.0201 - acc: 0.9934 - val_loss: 0.0381 - val_acc: 0.9908\n",
      "Epoch 25/50\n",
      "55000/55000 [==============================] - 9s 158us/step - loss: 0.0186 - acc: 0.9937 - val_loss: 0.0376 - val_acc: 0.9900\n",
      "Epoch 26/50\n",
      "55000/55000 [==============================] - 9s 158us/step - loss: 0.0178 - acc: 0.9937 - val_loss: 0.0327 - val_acc: 0.9930\n",
      "Epoch 27/50\n",
      "55000/55000 [==============================] - 9s 158us/step - loss: 0.0170 - acc: 0.9944 - val_loss: 0.0316 - val_acc: 0.9926\n",
      "Epoch 28/50\n",
      "55000/55000 [==============================] - 9s 159us/step - loss: 0.0162 - acc: 0.9948 - val_loss: 0.0296 - val_acc: 0.9934\n",
      "Epoch 29/50\n",
      "55000/55000 [==============================] - 9s 158us/step - loss: 0.0165 - acc: 0.9947 - val_loss: 0.0288 - val_acc: 0.9930\n",
      "Epoch 30/50\n",
      "55000/55000 [==============================] - 9s 158us/step - loss: 0.0151 - acc: 0.9953 - val_loss: 0.0281 - val_acc: 0.9922\n",
      "Epoch 31/50\n",
      "55000/55000 [==============================] - 9s 158us/step - loss: 0.0146 - acc: 0.9952 - val_loss: 0.0293 - val_acc: 0.9934\n",
      "Epoch 32/50\n",
      "55000/55000 [==============================] - 9s 158us/step - loss: 0.0144 - acc: 0.9953 - val_loss: 0.0336 - val_acc: 0.9924\n",
      "Epoch 33/50\n",
      "55000/55000 [==============================] - 9s 159us/step - loss: 0.0131 - acc: 0.9956 - val_loss: 0.0350 - val_acc: 0.9928\n",
      "Epoch 34/50\n",
      "55000/55000 [==============================] - 9s 159us/step - loss: 0.0136 - acc: 0.9954 - val_loss: 0.0349 - val_acc: 0.9920\n",
      "Epoch 35/50\n",
      "55000/55000 [==============================] - 9s 158us/step - loss: 0.0116 - acc: 0.9962 - val_loss: 0.0373 - val_acc: 0.9922\n",
      "Epoch 36/50\n",
      "55000/55000 [==============================] - 9s 158us/step - loss: 0.0128 - acc: 0.9957 - val_loss: 0.0384 - val_acc: 0.9918\n",
      "Epoch 37/50\n",
      "55000/55000 [==============================] - 9s 158us/step - loss: 0.0129 - acc: 0.9957 - val_loss: 0.0360 - val_acc: 0.9932\n",
      "Epoch 38/50\n",
      "55000/55000 [==============================] - 9s 158us/step - loss: 0.0114 - acc: 0.9962 - val_loss: 0.0360 - val_acc: 0.9916\n",
      "Epoch 39/50\n",
      "55000/55000 [==============================] - 9s 158us/step - loss: 0.0111 - acc: 0.9963 - val_loss: 0.0374 - val_acc: 0.9908\n",
      "Epoch 40/50\n",
      "55000/55000 [==============================] - 9s 158us/step - loss: 0.0110 - acc: 0.9965 - val_loss: 0.0402 - val_acc: 0.9916\n",
      "Epoch 41/50\n",
      "55000/55000 [==============================] - 9s 158us/step - loss: 0.0100 - acc: 0.9967 - val_loss: 0.0329 - val_acc: 0.9936\n",
      "Epoch 42/50\n",
      "55000/55000 [==============================] - 9s 158us/step - loss: 0.0103 - acc: 0.9964 - val_loss: 0.0362 - val_acc: 0.9932\n",
      "Epoch 43/50\n",
      "55000/55000 [==============================] - 9s 158us/step - loss: 0.0094 - acc: 0.9969 - val_loss: 0.0344 - val_acc: 0.9930\n",
      "Epoch 44/50\n",
      "55000/55000 [==============================] - 9s 157us/step - loss: 0.0095 - acc: 0.9967 - val_loss: 0.0375 - val_acc: 0.9926\n",
      "Epoch 45/50\n",
      "55000/55000 [==============================] - 9s 159us/step - loss: 0.0098 - acc: 0.9966 - val_loss: 0.0359 - val_acc: 0.9926\n",
      "Epoch 46/50\n",
      "55000/55000 [==============================] - 9s 158us/step - loss: 0.0095 - acc: 0.9968 - val_loss: 0.0319 - val_acc: 0.9932\n",
      "Epoch 47/50\n",
      "55000/55000 [==============================] - 9s 159us/step - loss: 0.0075 - acc: 0.9973 - val_loss: 0.0381 - val_acc: 0.9934\n",
      "Epoch 48/50\n",
      "55000/55000 [==============================] - 9s 159us/step - loss: 0.0078 - acc: 0.9973 - val_loss: 0.0393 - val_acc: 0.9918\n",
      "Epoch 49/50\n",
      "55000/55000 [==============================] - 9s 158us/step - loss: 0.0079 - acc: 0.9972 - val_loss: 0.0357 - val_acc: 0.9934\n",
      "Epoch 50/50\n",
      "55000/55000 [==============================] - 9s 158us/step - loss: 0.0077 - acc: 0.9975 - val_loss: 0.0412 - val_acc: 0.9930\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.models.Sequential at 0x7f359b0a8e50>"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "if not os.path.isdir(model_dir):\n",
    "    os.makedirs(model_dir)\n",
    "\n",
    "train(MNIST(), model_dir+\"/mnist_mixedpool\", [32, 32, 64, 64, 200, 200], num_epochs=50)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Mixedpool on Spatially transformed examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<bound method Sequential.summary of <keras.models.Sequential object at 0x7f34a8ab5150>>\n",
      "Train on 55090 samples, validate on 90 samples\n",
      "Epoch 1/50\n",
      "55090/55090 [==============================] - 9s 169us/step - loss: 0.7667 - acc: 0.7340 - val_loss: 1.2888 - val_acc: 0.4778\n",
      "Epoch 2/50\n",
      "55090/55090 [==============================] - 9s 155us/step - loss: 0.1687 - acc: 0.9486 - val_loss: 1.1280 - val_acc: 0.5889\n",
      "Epoch 3/50\n",
      "55090/55090 [==============================] - 9s 155us/step - loss: 0.1214 - acc: 0.9624 - val_loss: 1.3142 - val_acc: 0.5000\n",
      "Epoch 4/50\n",
      "55090/55090 [==============================] - 9s 155us/step - loss: 0.0937 - acc: 0.9710 - val_loss: 1.4767 - val_acc: 0.5111\n",
      "Epoch 5/50\n",
      "55090/55090 [==============================] - 9s 154us/step - loss: 0.0788 - acc: 0.9754 - val_loss: 1.2708 - val_acc: 0.5222\n",
      "Epoch 6/50\n",
      "55090/55090 [==============================] - 9s 155us/step - loss: 0.0695 - acc: 0.9792 - val_loss: 1.7961 - val_acc: 0.3889\n",
      "Epoch 7/50\n",
      "55090/55090 [==============================] - 9s 155us/step - loss: 0.0635 - acc: 0.9806 - val_loss: 1.5951 - val_acc: 0.4000\n",
      "Epoch 8/50\n",
      "55090/55090 [==============================] - 9s 155us/step - loss: 0.0564 - acc: 0.9828 - val_loss: 1.7510 - val_acc: 0.4111\n",
      "Epoch 9/50\n",
      "55090/55090 [==============================] - 9s 155us/step - loss: 0.0503 - acc: 0.9847 - val_loss: 1.8109 - val_acc: 0.4000\n",
      "Epoch 10/50\n",
      "55090/55090 [==============================] - 9s 155us/step - loss: 0.0472 - acc: 0.9850 - val_loss: 2.0480 - val_acc: 0.3444\n",
      "Epoch 11/50\n",
      "55090/55090 [==============================] - 9s 155us/step - loss: 0.0430 - acc: 0.9865 - val_loss: 1.8520 - val_acc: 0.4222\n",
      "Epoch 12/50\n",
      "55090/55090 [==============================] - 9s 155us/step - loss: 0.0410 - acc: 0.9873 - val_loss: 2.0817 - val_acc: 0.3444\n",
      "Epoch 13/50\n",
      "55090/55090 [==============================] - 9s 155us/step - loss: 0.0367 - acc: 0.9884 - val_loss: 1.8364 - val_acc: 0.3778\n",
      "Epoch 14/50\n",
      "55090/55090 [==============================] - 9s 155us/step - loss: 0.0365 - acc: 0.9887 - val_loss: 2.0213 - val_acc: 0.3778\n",
      "Epoch 15/50\n",
      "55090/55090 [==============================] - 9s 155us/step - loss: 0.0330 - acc: 0.9896 - val_loss: 2.2916 - val_acc: 0.3222\n",
      "Epoch 16/50\n",
      "55090/55090 [==============================] - 9s 155us/step - loss: 0.0304 - acc: 0.9905 - val_loss: 2.2637 - val_acc: 0.3444\n",
      "Epoch 17/50\n",
      "31616/55090 [================>.............] - ETA: 3s - loss: 0.0278 - acc: 0.9909"
     ]
    }
   ],
   "source": [
    "if not os.path.isdir(model_dir):\n",
    "    os.makedirs(model_dir)\n",
    "\n",
    "train(MNIST_Adv(), model_dir+\"/mnist_mixedpool_adv\", [32, 32, 64, 64, 200, 200], num_epochs=50, init = None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train GatedPool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation, Flatten, Input\n",
    "from keras.layers import Conv2D, MaxPooling2D, AveragePooling2D\n",
    "from keras.optimizers import SGD\n",
    "from keras.models import Model\n",
    "\n",
    "import tensorflow as tf\n",
    "# from setup_mnist import MNIST\n",
    "# from setup_cifar import CIFAR\n",
    "import os\n",
    "\n",
    "def train_gated(data, file_name, params, num_epochs=50, batch_size=128, train_temp=1, init=None):\n",
    "\n",
    "    model = Sequential()\n",
    "    model.add(Conv2D(params[0], (3, 3),\n",
    "                            input_shape=data.train_data.shape[1:]))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Conv2D(params[1], (3, 3)))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(GatedPooling2D(fil=params[1] ))\n",
    "    \n",
    "    model.add(Conv2D(params[2], (3, 3)))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Conv2D(params[3], (3, 3)))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(GatedPooling2D( fil=params[3]))\n",
    "\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(params[4]))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(params[5]))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Dense(10))\n",
    "    # no softmax\n",
    "    \n",
    "    print(model.summary)\n",
    "   \n",
    "    if init != None:\n",
    "        model.load_weights(init)\n",
    "\n",
    "    def fn(correct, predicted):\n",
    "        return tf.nn.softmax_cross_entropy_with_logits(labels=correct,\n",
    "                                                       logits=predicted/train_temp)\n",
    "\n",
    "    sgd = SGD(lr=0.01, decay=1e-6, momentum=0.9, nesterov=True)\n",
    "    \n",
    "    model.compile(loss=fn,\n",
    "                  optimizer=sgd,\n",
    "                  metrics=['accuracy'])\n",
    "    \n",
    "    model.fit(data.train_data, data.train_labels,\n",
    "              batch_size=batch_size,\n",
    "              validation_data=(data.validation_data, data.validation_labels),\n",
    "              epochs=num_epochs,\n",
    "              shuffle=True)\n",
    "    \n",
    "\n",
    "    if file_name != None:\n",
    "        model.save(file_name)\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "('Keyword argument not understood:', 'fil')",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-82-abf61fac20c4>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      2\u001b[0m     \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmakedirs\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel_dir\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m \u001b[0mtrain_gated\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mMNIST\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmodel_dir\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;34m\"/mnist_gatedpool\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;36m32\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m32\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m64\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m64\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m200\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m200\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnum_epochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m50\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-81-49485febb7ae>\u001b[0m in \u001b[0;36mtrain_gated\u001b[1;34m(data, file_name, params, num_epochs, batch_size, train_temp, init)\u001b[0m\n\u001b[0;32m     19\u001b[0m     \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mConv2D\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mparams\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m3\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     20\u001b[0m     \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mActivation\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'relu'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 21\u001b[1;33m     \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mGatedPooling2D\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfil\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mparams\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     22\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     23\u001b[0m     \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mConv2D\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mparams\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m3\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/usr/local/lib/python2.7/dist-packages/keras/legacy/interfaces.pyc\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     89\u001b[0m                 warnings.warn('Update your `' + object_name +\n\u001b[0;32m     90\u001b[0m                               '` call to the Keras 2 API: ' + signature, stacklevel=2)\n\u001b[1;32m---> 91\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     92\u001b[0m         \u001b[0mwrapper\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_original_function\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     93\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/usr/local/lib/python2.7/dist-packages/keras/layers/pooling.pyc\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, pool_size, strides, padding, data_format, **kwargs)\u001b[0m\n\u001b[0;32m    213\u001b[0m                  data_format=None, **kwargs):\n\u001b[0;32m    214\u001b[0m         super(MaxPooling2D, self).__init__(pool_size, strides, padding,\n\u001b[1;32m--> 215\u001b[1;33m                                            data_format, **kwargs)\n\u001b[0m\u001b[0;32m    216\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    217\u001b[0m     def _pooling_function(self, inputs, pool_size, strides,\n",
      "\u001b[1;32m/usr/local/lib/python2.7/dist-packages/keras/layers/pooling.pyc\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, pool_size, strides, padding, data_format, **kwargs)\u001b[0m\n\u001b[0;32m    121\u001b[0m     def __init__(self, pool_size=(2, 2), strides=None, padding='valid',\n\u001b[0;32m    122\u001b[0m                  data_format=None, **kwargs):\n\u001b[1;32m--> 123\u001b[1;33m         \u001b[0msuper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_Pooling2D\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    124\u001b[0m         \u001b[0mdata_format\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mconv_utils\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnormalize_data_format\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata_format\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    125\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mstrides\u001b[0m \u001b[1;32mis\u001b[0m \u001b[0mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/usr/local/lib/python2.7/dist-packages/keras/engine/topology.pyc\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, **kwargs)\u001b[0m\n\u001b[0;32m    290\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mkwarg\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    291\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mkwarg\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mallowed_kwargs\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 292\u001b[1;33m                 \u001b[1;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Keyword argument not understood:'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwarg\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    293\u001b[0m         \u001b[0mname\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'name'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    294\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: ('Keyword argument not understood:', 'fil')"
     ]
    }
   ],
   "source": [
    "if not os.path.isdir(model_dir):\n",
    "    os.makedirs(model_dir)\n",
    "\n",
    "train_gated(MNIST(), model_dir+\"/mnist_gatedpool\", [32, 32, 64, 64, 200, 200], num_epochs=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
